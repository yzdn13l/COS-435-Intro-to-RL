{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TAi7TP9xnEK"
      },
      "source": [
        "# The CartPole Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfCnxEi52C0Q"
      },
      "source": [
        "Below is the Cartpole environment we saw in class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FriEEkbOxuaz",
        "outputId": "035bd42e-a8e4-47fb-8d1a-805700d30356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym[classic_control] in /home/warrenz/miniconda3/envs/HWs/lib/python3.9/site-packages (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /home/warrenz/miniconda3/envs/HWs/lib/python3.9/site-packages (from gym[classic_control]) (1.22.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/warrenz/miniconda3/envs/HWs/lib/python3.9/site-packages (from gym[classic_control]) (3.1.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.8.0 in /home/warrenz/miniconda3/envs/HWs/lib/python3.9/site-packages (from gym[classic_control]) (7.0.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /home/warrenz/miniconda3/envs/HWs/lib/python3.9/site-packages (from gym[classic_control]) (0.0.8)\n",
            "Requirement already satisfied: pygame==2.1.0 in /home/warrenz/miniconda3/envs/HWs/lib/python3.9/site-packages (from gym[classic_control]) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/warrenz/miniconda3/envs/HWs/lib/python3.9/site-packages (from importlib_metadata>=4.8.0->gym[classic_control]) (3.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# pip install --upgrade gym\n",
        "!pip install gym[classic_control]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "t3ltIad5GdZp"
      },
      "outputs": [],
      "source": [
        "### use contrastive_rl kernel\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "y04tq0F2lNSe"
      },
      "outputs": [],
      "source": [
        "env = gym.make('CartPole-v1', render_mode='rgb_array')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sktyySdAxvXq",
        "outputId": "dbf4eecc-ca12-4096-89e9-d717eb387ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions:\n",
            "Discrete(2)\n"
          ]
        }
      ],
      "source": [
        "print('Actions:')\n",
        "print(env.action_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK5sBbWVxxk8",
        "outputId": "5352f71a-682d-4fc8-fa4b-98dca8b7e6de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h07Dg4tqx0A3",
        "outputId": "c8e56202-4324-44be-fa71-d038e4dc67ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observations:\n",
            "shape: (4,)\n",
            "low: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
            "high: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
          ]
        }
      ],
      "source": [
        "print('Observations:')\n",
        "print('shape:', env.observation_space.shape)\n",
        "print('low:', env.observation_space.low)\n",
        "print('high:', env.observation_space.high)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOQKuimYx2mB",
        "outputId": "4554e6ab-70fc-4bec-cd60-8426a8187400"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.02372011, -0.00124597,  0.02747648,  0.01913693], dtype=float32)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s, _ = env.reset()\n",
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rbxk4fQyKC2",
        "outputId": "a348c692-1515-4e82-d23c-ef1b78c80fec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s: [ 0.02369519 -0.19675097  0.02785922  0.3203608 ]\n",
            "r: 1.0\n",
            "done: False\n"
          ]
        }
      ],
      "source": [
        "a = 0\n",
        "s, r, done, _, _ = env.step(a)\n",
        "print(f\"s: {s}\")\n",
        "print(f\"r: {r}\")\n",
        "print(f\"done: {done}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "_ZombCYFyXDr",
        "outputId": "d04b989f-e9db-4013-f5a6-1fca3704fe71"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(env.render())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "LIqAqH93yZpo",
        "outputId": "41cfd5a1-240f-4bfc-b4da-5a9fd06be1ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total reward: 99.3\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def policy(observation):\n",
        "  action = np.random.choice([0, 1])\n",
        "  LEFT, RIGHT = 0, 1\n",
        "  cart_pos, cart_vel, pole_angle, pole_angular_vel = observation\n",
        "\n",
        "  # TODO:\n",
        "  if pole_angle + pole_angular_vel < 0:\n",
        "    action = LEFT\n",
        "  else:\n",
        "    action = RIGHT\n",
        "\n",
        "  return action\n",
        "\n",
        "discount = 0.99\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "\n",
        "img = plt.imshow(env.render())\n",
        "def render():\n",
        "  rgb = env.render()\n",
        "  if done:\n",
        "    rgb[:, :, 1:] = rgb[:, :, 1:] / 2\n",
        "  img.set_data(rgb)\n",
        "  plt.axis('off')\n",
        "  display.display(plt.gcf())\n",
        "  display.clear_output(wait=True)\n",
        "\n",
        "\n",
        "s, _ = env.reset()\n",
        "for t in range(env._max_episode_steps):\n",
        "#   print(t)\n",
        "  action = policy(s)\n",
        "  s, r, done, _, _ = env.step(action)\n",
        "  render()\n",
        "  total_reward += (discount**t) * r\n",
        "  if done:\n",
        "    break\n",
        "print('Total reward: %.1f' % total_reward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y88t4FRkyf3i"
      },
      "source": [
        "##  Question 1: Implement MPC + CEM\n",
        "1. Write two functions from scratch:\n",
        "   - cross_entropy_method(mean_probs, horizon, num_actions, sample_size, elite_frac, cem_iterations, evaluate_fn)\n",
        "   - mpc_control(env, horizon, cem_iterations, sample_size, elite_frac, gamma)\n",
        "\n",
        "2. cross_entropy_method(...)\n",
        "   - Maintains or updates a probability distribution over action sequences (length H).\n",
        "   - Samples multiple candidates, evaluates them, selects \"elite\" sequences, and refits the distribution.\n",
        "   - Returns the best sequence found (and optionally the final distribution).\n",
        "\n",
        "3. mpc_control(env, horizon, cem_iterations, sample_size, elite_frac, gamma)\n",
        "   - On each environment step, calls the above CEM to get an action sequence of length H from the current state.\n",
        "   - Executes the first action in the real env, obtains next state, continues until done.\n",
        "   - If needed, you can \"shift\" or \"reset\" the distribution between steps.\n",
        "\n",
        "Notes: In your solution, carefully implement how you evaluate each candidate action sequence from the current state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "uqCsTBGZzFiU"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_method(mean_probs, horizon, num_actions, sample_size, elite_frac, cem_iterations, evaluate_fn):\n",
        "    \"\"\"\n",
        "    TODO: Implement the Cross-Entropy Method (CEM).\n",
        "\n",
        "    Args:\n",
        "        mean_probs (np.ndarray): shape (horizon, num_actions),\n",
        "            the probability distribution over actions at each step.\n",
        "        horizon (int): planning horizon (number of steps).\n",
        "        num_actions (int): discrete action dimension (CartPole has 2).\n",
        "        sample_size (int): how many candidate sequences to sample each iteration.\n",
        "        elite_frac (float): fraction of top sequences to keep as \"elite\".\n",
        "        cem_iterations (int): number of distribution-refinement iterations.\n",
        "        evaluate_fn (callable): function(seq) -> returns a scalar cumulative reward for that action sequence.\n",
        "\n",
        "    Returns:\n",
        "        best_seq (np.ndarray): best action sequence found (shape: (horizon,))\n",
        "        final_probs (np.ndarray): the final distribution (horizon x num_actions).\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    final_probs = mean_probs\n",
        "    for i in range(cem_iterations):\n",
        "        samples = np.array([np.random.choice(num_actions, sample_size, p=final_probs[t]) for t in range(horizon)]) # (horizon, sample_size)\n",
        "        samples = samples.T # (sample_size, horizon)\n",
        "        rewards = np.array([evaluate_fn(seq) for seq in samples]) # (sample_size,)\n",
        "        elite_inds = rewards.argsort()[-int(sample_size * elite_frac):] # (elite_size,)\n",
        "        elite_samples = samples[elite_inds] # (elite_size, horizon)\n",
        "        \n",
        "        elite_probs = np.zeros((horizon, num_actions))\n",
        "        for t in range(horizon):\n",
        "            for a in range(num_actions):\n",
        "                elite_probs[t, a] = np.sum(elite_samples[:, t] == a) / elite_samples.shape[0]\n",
        "        final_probs = elite_probs\n",
        "        \n",
        "    best_seq = elite_samples[0] # (horizon,)\n",
        "    # print(f\"best_seq: {best_seq}\")\n",
        "    # print(f\"best reward: {rewards[elite_inds[0]]}\")\n",
        "    return best_seq, final_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "c9p7Z5Zm0C-G"
      },
      "outputs": [],
      "source": [
        "def mpc_control(env, horizon=15, cem_iterations=4, sample_size=200, elite_frac=0.1, gamma=1.0):\n",
        "    \"\"\"\n",
        "    TODO: Implement MPC with CEM for the CartPole environment.\n",
        "\n",
        "    On each environment step:\n",
        "      1) define an evaluate_fn that simulates a candidate sequence from the *current state* (or an approximation).\n",
        "      2) call cross_entropy_method(...) to get the best sequence of length 'horizon'.\n",
        "      3) execute the first action from 'best_seq'.\n",
        "      4) repeat until done or max steps reached.\n",
        "\n",
        "    Return:\n",
        "        total_reward (float): total (possibly discounted) reward of this episode.\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###      \n",
        "    def evaluate_fn(seq, temp_env=env):\n",
        "        total_ret = 0.0\n",
        "        discount_factor = 1.0\n",
        "        for action in seq:\n",
        "            # step\n",
        "            s_next, rew, done_, _, _ = temp_env.step(action)\n",
        "            total_ret += discount_factor * rew\n",
        "            discount_factor *= gamma\n",
        "            if done_:\n",
        "                break\n",
        "        return total_ret\n",
        "      \n",
        "    mean_probs = np.ones((horizon, env.action_space.n)) / env.action_space.n\n",
        "    done = False\n",
        "    s, _ = env.reset()\n",
        "    total_reward = 0\n",
        "    for t in range(env._max_episode_steps):\n",
        "        seq, _ = cross_entropy_method(mean_probs, \n",
        "                                   horizon, \n",
        "                                   env.action_space.n, \n",
        "                                   sample_size, \n",
        "                                   elite_frac, \n",
        "                                   cem_iterations, \n",
        "                                   lambda seq: evaluate_fn(seq, copy.deepcopy(env)))\n",
        "        action = seq[0]\n",
        "        s, r, done, _, _ = env.step(action)\n",
        "        # print(f\"t: {t}, action: {action}, r: {r}\")\n",
        "        total_reward += (gamma**t) * r\n",
        "        if done:\n",
        "            break\n",
        "    return total_reward\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "2m4pKdRG2-ii"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MPC Episode 1] Return = 378.00\n",
            "[MPC Episode 2] Return = 336.00\n",
            "[MPC Episode 3] Return = 342.00\n",
            "[MPC Episode 4] Return = 500.00\n",
            "[MPC Episode 5] Return = 171.00\n",
            "Average Return (MPC + CEM): 345.4\n"
          ]
        }
      ],
      "source": [
        "def run_mpc_cem_demo():\n",
        "    \"\"\"\n",
        "    After implementing cross_entropy_method(...) and mpc_control(...),\n",
        "    run multiple episodes to evaluate performance.\n",
        "    \"\"\"\n",
        "    new_env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
        "\n",
        "    episodes = 5\n",
        "    horizon = 15\n",
        "    total_rewards = []\n",
        "    for ep in range(episodes):\n",
        "        ep_return = mpc_control(new_env, horizon=horizon, cem_iterations=4,\n",
        "                                sample_size=200, elite_frac=0.1, gamma=1.0)\n",
        "        total_rewards.append(ep_return)\n",
        "        print(f\"[MPC Episode {ep+1}] Return = {ep_return:.2f}\")\n",
        "    print(\"Average Return (MPC + CEM):\", np.mean(total_rewards))\n",
        "\n",
        "# Uncomment to test the MPC + CEM solution:\n",
        "run_mpc_cem_demo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v83gIJVa0zFS"
      },
      "source": [
        "## Zero-Order Policy Search With CEM\n",
        "Now that you've seen how to use CEM for searching action sequences (MPC), let's re-use the same concept to search directly for a policy parameter vector. This is often called \"Zero-Order Policy Search,\" because we do not require gradients of the policy. We only need to evaluate how good each parameter vector is.\n",
        "\n",
        "In this question, you need to\n",
        "1. Define a parametric policy for CartPole.\n",
        "2. Reuse your CEM approach to search over w in $R^4$ (since CartPole state is 4D).\n",
        "3. Evaluate each sampled w by running a full episode, gather total reward,\n",
        "   pick elites, update distribution.\n",
        "4. After some iterations, you get a final w. Evaluate that policy\n",
        "   and report average return over multiple episodes.\n",
        "\n",
        "Below is a skeleton with TODO for you to fill in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "jYwOrlr80rug"
      },
      "outputs": [],
      "source": [
        "def choose_action(w, obs):\n",
        "    \"\"\"\n",
        "    A simple linear policy for CartPole:\n",
        "      action = 1 if w dot obs > 0 else 0.\n",
        "    w, obs: shape (4,)\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    action = 1 if np.dot(w, obs) > 0 else 0\n",
        "    return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "61IrkA9f0t-e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rollout_episode(env, w):\n",
        "    \"\"\"\n",
        "    Run one full episode in 'env' using param 'w'.\n",
        "    Return total (undiscounted) reward.\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    s, _ = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    for t in range(env._max_episode_steps):\n",
        "        action = choose_action(w, s)\n",
        "        s, r, done, _, _ = env.step(action)\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "    return total_reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "lXdwz_vN0uuq"
      },
      "outputs": [],
      "source": [
        "def train_cem_policy(env, dim=4, cem_iterations=10, sample_size=50, elite_frac=0.2):\n",
        "    \"\"\"\n",
        "    TODOs: Zero-Order Policy Search with CEM.\n",
        "      1) Maintain param distribution (mean, std) in R^dim\n",
        "      2) For iteration in [1..cem_iterations]:\n",
        "         - sample 'sample_size' param vectors\n",
        "         - evaluate each, get total reward\n",
        "         - pick top 'elite_frac', update distribution\n",
        "      3) Return best param or final mean\n",
        "    \"\"\"\n",
        "\n",
        "    # Example init (feel free to change it)\n",
        "    mean = np.zeros(dim)\n",
        "    std = np.ones(dim)*2.0\n",
        "    best_w = mean.copy()\n",
        "    best_score = -1e9\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "    for _ in range(cem_iterations):\n",
        "        samples = np.random.normal(mean, std, (sample_size, dim))\n",
        "        rewards = np.array([rollout_episode(env, w) for w in samples])\n",
        "        elite_inds = rewards.argsort()[-int(sample_size * elite_frac):]\n",
        "        elite_samples = samples[elite_inds]\n",
        "        mean = elite_samples.mean(axis=0)\n",
        "        std = elite_samples.std(axis=0)\n",
        "        best_score = rewards[elite_inds[-1]]\n",
        "        best_w = elite_samples[-1]\n",
        "    return best_w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "ESd8wLhs01YJ"
      },
      "outputs": [],
      "source": [
        "def eval_policy(env, w, episodes=5):\n",
        "    \"\"\"\n",
        "    TODOs: Evaluate policy param 'w' over multiple episodes\n",
        "    and return average total reward.\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    total_rewards = [rollout_episode(env, w) for _ in range(episodes)]\n",
        "    return np.mean(total_rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "40Bey9iw37Gz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final policy average return (Zero-Order Search) = 148.20\n"
          ]
        }
      ],
      "source": [
        "def run_zero_order_cem_demo():\n",
        "    \"\"\"\n",
        "    Demo for Problem 2: train & evaluate a linear policy with CEM.\n",
        "    \"\"\"\n",
        "    env_zo = gym.make('CartPole-v1')\n",
        "    env_zo._max_episode_steps = 200\n",
        "    w_star = train_cem_policy(env_zo, dim=4, cem_iterations=10, sample_size=10, elite_frac=0.2)\n",
        "    avg_ret = eval_policy(env_zo, w_star, episodes=5)\n",
        "    print(f\"\\nFinal policy average return (Zero-Order Search) = {avg_ret:.2f}\")\n",
        "\n",
        "\n",
        "run_zero_order_cem_demo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "HWs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
